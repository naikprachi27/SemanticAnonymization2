# -*- coding: utf-8 -*-
"""Ampligraph_TransE_FB13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gshQJzLVy5XQSGGURyzGTi18dveJlgpt
"""

# !pip install ampligraph

# !pip install tensorflow==2.12


# type(X["train"])

from ampligraph.datasets import load_from_csv
X = {"train":[], "test":[], "valid":[]}
X["train"] = load_from_csv("Anonymised_Data_raw/", "Final_training_data_for_KGE.tsv", sep='\t')
X["test"] = load_from_csv("Datasets/Anonymised_dataset/fb13/mapping_output/", "numbered_2.tsv", sep='\t')
X["valid"] = load_from_csv("Datasets/Anonymised_dataset/fb13/mapping_output/", "numbered_3.tsv", sep='\t')

import pandas as pd
train = pd.DataFrame(X["train"])
test = pd.DataFrame(X["test"])
valid = pd.DataFrame(X["valid"])

len(train.iloc[:,0].unique())  # originalNodes - discardedNodes + fakeNodes
train_sub_set = set(train.iloc[:,0].unique())
train_rel_set = set(train.iloc[:,1].unique())
train_obj_set = set(train.iloc[:,2].unique())

test_sub_set = set(test.iloc[:,0].unique())
test_rel_set = set(test.iloc[:,1].unique())
test_obj_set = set(test.iloc[:,2].unique())

valid_sub_set = set(valid.iloc[:,0].unique())
valid_rel_set = set(valid.iloc[:,1].unique())
valid_obj_set = set(valid.iloc[:,2].unique())

print("number of (test sub - train sub)", (test_sub_set.difference(train_sub_set)))
print("number of (test rel - train rel)", (test_rel_set.difference(train_rel_set)))
print("number of (test obj - train obj)", (test_obj_set.difference(train_obj_set)))

print("number of (valid sub - train sub)", len(valid_sub_set.difference(train_sub_set)))
print("number of (valid rel - train rel)", len(valid_rel_set.difference(train_rel_set)))
print("number of (valid obj - train obj)", len(valid_obj_set.difference(train_obj_set)))



X["valid"].shape

import tensorflow as tf
print(tf.version.VERSION)

import ampligraph
ampligraph.__version__



from ampligraph.latent_features import ScoringBasedEmbeddingModel
from ampligraph.latent_features.loss_functions import get as get_loss
from ampligraph.latent_features.regularizers import get as get_regularizer
import numpy as np

model = ScoringBasedEmbeddingModel(k=100,  #embedding size
                                   eta=10,
                                   scoring_type='TransE')
# Optimizer, loss and regularizer definition
optim = tf.keras.optimizers.Adam(learning_rate=1e-3)
loss = get_loss('pairwise', {'margin': 0.5})
regularizer = get_regularizer('LP', {'p': 2, 'lambda': 1e-5})

model.compile(optimizer=optim, loss=loss, entity_relation_regularizer=regularizer)

filter = {'test' : np.concatenate((X["train"], X["valid"], X["test"]))}


# Early Stopping callback
checkpoint = tf.keras.callbacks.EarlyStopping(
    monitor='val_{}'.format('hits10'),
    min_delta=0,
    patience=5,
    verbose=1,
    mode='max',
    restore_best_weights=True
)

# Fit the model on training and validation set
model.fit(X["train"],
          batch_size=int(X["train"].shape[0] / 10),
          epochs=200,                    # Number of training epochs
          validation_freq=20,           # Epochs between successive validation
          validation_burn_in=100,       # Epoch to start validation
          validation_data=X["valid"],   # Validation data
          validation_filter=filter,     # Filter positives from validation corruptions
          callbacks=[checkpoint],       # Early stopping callback (more from tf.keras.callbacks are supported)
          verbose=True                  # Enable stdout messages
          )

from ampligraph.utils import save_model

# Save the model
example_name = "KGModels/Ampligraph_TransE_FB13.pkl"
save_model(model, model_name_path=example_name)

from ampligraph.evaluation import mrr_score, hits_at_n_score

ranks = model.evaluate(X["test"],
                       use_filter=filter,
                       corrupt_side='s,o')

# compute and print metrics:
mrr = mrr_score(ranks)
hits_10 = hits_at_n_score(ranks, n=10)
hits_1 = hits_at_n_score(ranks, n=1)
hits_5 = hits_at_n_score(ranks, n=5)
print("MRR: %f, Hits@10: %f" % (mrr, hits_10))
print("hits_1: %f, hits_5: %f" % (hits_1, hits_5))

# !unzip -q /content/Ampligraph_ComplEx_inbuiltDataset.zip -d ampligraph_DistMult_inbuiltDataset3lacs1_new.pkl/

# from ampligraph.utils import save_model, restore_model

# # Restore the model
# example_name = "KGModels/Ampligraph_TransE_FB13.pkl"
# restored_model = restore_model(model_name_path=example_name)

# if restored_model.is_fitted:
#     print('The model is fit!')
# else:
#     print('The model is not fit! Did you skip a step?')

# invalid_keys = model.get_invalid_keys(X["test"])

# print("Test : ")
# print("Invalid keys sub:", (invalid_keys[0]))
# print("Invalid keys rel:", (invalid_keys[1]))
# print("Invalid keys obj:", (invalid_keys[2]))
# invalid_sub_set = set(invalid_keys[0])

# invalid_keys = model.get_invalid_keys(X["valid"])
# print("valid : ")
# print("Invalid keys sub:", (invalid_keys[0]))
# print("Invalid keys rel:", (invalid_keys[1]))
# print("Invalid keys obj:", (invalid_keys[2]))

# len(invalid_sub_set)


# import pandas as pd
# from ampligraph.evaluation import mrr_score, hits_at_n_score
# import numpy as np

# filter = {'test' : np.concatenate((X["train"], X["valid"], X["test"]))}
# ranks = restored_model.evaluate(X["test"],
#                        use_filter=filter,
#                        corrupt_side='s,o')

# # compute and print metrics:
# mrr = mrr_score(ranks)
# hits_10 = hits_at_n_score(ranks, n=10)
# hits_1 = hits_at_n_score(ranks, n=1)
# hits_5 = hits_at_n_score(ranks, n=5)
# print("MRR: %f, Hits@10: %f" % (mrr, hits_10))
# print("hits_1: %f, hits_5: %f" % (hits_1, hits_5))

# max_rank = np.max(ranks[:,1])
# second_col = ranks[:,1]
# unique_vals = np.unique(second_col)

# if len(unique_vals) > 1:
#     second_max = unique_vals[-2]
# else:
#     second_max = None

# print(max_rank)
# print(second_max)
# zero_ranks = np.where(ranks[:,1] == 38617)[0]
# zero_ranks

